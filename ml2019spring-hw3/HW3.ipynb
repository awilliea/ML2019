{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15160409835848794422\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13304801861798122278\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 741035101400044884\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 8249530778\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16083498416915108452\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# 设置session\n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            feature\n",
       "0      0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1      0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2      2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3      4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4      6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv',engine='python')\n",
    "test = pd.read_csv('test.csv',engine='python')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = pd.to_numeric(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = np.array(['1','2','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for f in train['feature']:\n",
    "    temp = np.array(f.split(' ')).astype(int)\n",
    "    train_x.append(temp)\n",
    "\n",
    "train_x = np.array(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 2304)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x.reshape((28709,48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Keras libraries and packages\n",
    "from keras.models import Sequential #用來啟動 NN\n",
    "from keras.layers import Conv2D # Convolution Operation\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D # Pooling\n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense # Fully Connected Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared_home/willie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(48, 48, 1..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/shared_home/willie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "/shared_home/willie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/shared_home/willie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  app.launch_new_instance()\n",
      "/shared_home/willie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # initializing CNN\n",
    "\n",
    "model.add(Conv2D(32, 3, 3, input_shape = (48, 48,1), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(32, 3, 3, activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2))) \n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(Conv2D(64, 3, 3, activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(output_dim = 128, activation = 'relu')) \n",
    "model.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128   #每次训练或者test时的大小\n",
    "NUM_CLASSES = 7   # 结果分成十类 从 0-9\n",
    "EPOCHS = 12        # 我们训练12轮\n",
    "# img_rows ,img_cols = 28,28  图片原始大小时 28 * 28 其实我们拿到的时已经拉平的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "28709/28709 [==============================] - 23s 817us/step - loss: -36.6281 - acc: 0.0157\n",
      "Epoch 2/12\n",
      "28709/28709 [==============================] - 23s 811us/step - loss: -36.9414 - acc: 0.0152\n",
      "Epoch 3/12\n",
      "28709/28709 [==============================] - 23s 812us/step - loss: -36.9404 - acc: 0.0152\n",
      "Epoch 4/12\n",
      "28709/28709 [==============================] - 23s 811us/step - loss: -36.9453 - acc: 0.0152\n",
      "Epoch 5/12\n",
      "28709/28709 [==============================] - 23s 812us/step - loss: -36.9453 - acc: 0.0152\n",
      "Epoch 6/12\n",
      " 9088/28709 [========>.....................] - ETA: 15s - loss: -36.7405 - acc: 0.0152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ad02127c2a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS,\n\u001b[0;32m----> 2\u001b[0;31m           verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import initializers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 3591      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 4,183,815\n",
      "Trainable params: 4,179,847\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # initializing CNN\n",
    "model.add(Convolution2D(64, kernel_size=3, strides=1, padding=\"same\", input_shape=(48, 48, 1), kernel_initializer=initializers.he_normal(seed=None)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(128, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializers.he_normal(seed=None)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(256, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializers.he_normal(seed=None)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Convolution2D(512, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializers.he_normal(seed=None)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=initializers.he_normal(seed=None)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=initializers.he_normal(seed=None)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation(\"softmax\"))\n",
    "# model.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "optim = Adam()\n",
    "\n",
    "model.compile(optimizer=optim, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intEpochs = 100\n",
    "intBatchSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 70],\n",
       "         [ 80],\n",
       "         [ 82],\n",
       "         ..., \n",
       "         [ 52],\n",
       "         [ 43],\n",
       "         [ 41]],\n",
       "\n",
       "        [[ 65],\n",
       "         [ 61],\n",
       "         [ 58],\n",
       "         ..., \n",
       "         [ 56],\n",
       "         [ 52],\n",
       "         [ 44]],\n",
       "\n",
       "        [[ 50],\n",
       "         [ 43],\n",
       "         [ 54],\n",
       "         ..., \n",
       "         [ 49],\n",
       "         [ 56],\n",
       "         [ 47]],\n",
       "\n",
       "        ..., \n",
       "        [[ 91],\n",
       "         [ 65],\n",
       "         [ 42],\n",
       "         ..., \n",
       "         [ 72],\n",
       "         [ 56],\n",
       "         [ 43]],\n",
       "\n",
       "        [[ 77],\n",
       "         [ 82],\n",
       "         [ 79],\n",
       "         ..., \n",
       "         [105],\n",
       "         [ 70],\n",
       "         [ 46]],\n",
       "\n",
       "        [[ 77],\n",
       "         [ 72],\n",
       "         [ 84],\n",
       "         ..., \n",
       "         [106],\n",
       "         [109],\n",
       "         [ 82]]],\n",
       "\n",
       "\n",
       "       [[[151],\n",
       "         [150],\n",
       "         [147],\n",
       "         ..., \n",
       "         [129],\n",
       "         [140],\n",
       "         [120]],\n",
       "\n",
       "        [[151],\n",
       "         [149],\n",
       "         [149],\n",
       "         ..., \n",
       "         [122],\n",
       "         [141],\n",
       "         [137]],\n",
       "\n",
       "        [[151],\n",
       "         [151],\n",
       "         [156],\n",
       "         ..., \n",
       "         [109],\n",
       "         [123],\n",
       "         [146]],\n",
       "\n",
       "        ..., \n",
       "        [[188],\n",
       "         [188],\n",
       "         [121],\n",
       "         ..., \n",
       "         [185],\n",
       "         [185],\n",
       "         [186]],\n",
       "\n",
       "        [[188],\n",
       "         [187],\n",
       "         [196],\n",
       "         ..., \n",
       "         [186],\n",
       "         [182],\n",
       "         [187]],\n",
       "\n",
       "        [[186],\n",
       "         [184],\n",
       "         [185],\n",
       "         ..., \n",
       "         [193],\n",
       "         [183],\n",
       "         [184]]],\n",
       "\n",
       "\n",
       "       [[[231],\n",
       "         [212],\n",
       "         [156],\n",
       "         ..., \n",
       "         [ 44],\n",
       "         [ 27],\n",
       "         [ 16]],\n",
       "\n",
       "        [[229],\n",
       "         [175],\n",
       "         [148],\n",
       "         ..., \n",
       "         [ 27],\n",
       "         [ 35],\n",
       "         [ 27]],\n",
       "\n",
       "        [[214],\n",
       "         [156],\n",
       "         [157],\n",
       "         ..., \n",
       "         [ 28],\n",
       "         [ 22],\n",
       "         [ 28]],\n",
       "\n",
       "        ..., \n",
       "        [[241],\n",
       "         [245],\n",
       "         [250],\n",
       "         ..., \n",
       "         [ 57],\n",
       "         [101],\n",
       "         [146]],\n",
       "\n",
       "        [[246],\n",
       "         [250],\n",
       "         [252],\n",
       "         ..., \n",
       "         [ 78],\n",
       "         [105],\n",
       "         [162]],\n",
       "\n",
       "        [[250],\n",
       "         [251],\n",
       "         [250],\n",
       "         ..., \n",
       "         [ 88],\n",
       "         [110],\n",
       "         [152]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 74],\n",
       "         [ 81],\n",
       "         [ 87],\n",
       "         ..., \n",
       "         [189],\n",
       "         [191],\n",
       "         [192]],\n",
       "\n",
       "        [[ 78],\n",
       "         [ 82],\n",
       "         [ 89],\n",
       "         ..., \n",
       "         [185],\n",
       "         [189],\n",
       "         [193]],\n",
       "\n",
       "        [[ 81],\n",
       "         [ 86],\n",
       "         [ 94],\n",
       "         ..., \n",
       "         [176],\n",
       "         [185],\n",
       "         [193]],\n",
       "\n",
       "        ..., \n",
       "        [[ 90],\n",
       "         [ 99],\n",
       "         [113],\n",
       "         ..., \n",
       "         [192],\n",
       "         [195],\n",
       "         [197]],\n",
       "\n",
       "        [[ 88],\n",
       "         [ 96],\n",
       "         [114],\n",
       "         ..., \n",
       "         [192],\n",
       "         [194],\n",
       "         [192]],\n",
       "\n",
       "        [[ 88],\n",
       "         [ 97],\n",
       "         [110],\n",
       "         ..., \n",
       "         [188],\n",
       "         [187],\n",
       "         [187]]],\n",
       "\n",
       "\n",
       "       [[[222],\n",
       "         [227],\n",
       "         [203],\n",
       "         ..., \n",
       "         [138],\n",
       "         [132],\n",
       "         [122]],\n",
       "\n",
       "        [[222],\n",
       "         [226],\n",
       "         [203],\n",
       "         ..., \n",
       "         [142],\n",
       "         [136],\n",
       "         [127]],\n",
       "\n",
       "        [[222],\n",
       "         [225],\n",
       "         [206],\n",
       "         ..., \n",
       "         [147],\n",
       "         [143],\n",
       "         [129]],\n",
       "\n",
       "        ..., \n",
       "        [[179],\n",
       "         [180],\n",
       "         [177],\n",
       "         ..., \n",
       "         [141],\n",
       "         [139],\n",
       "         [137]],\n",
       "\n",
       "        [[188],\n",
       "         [182],\n",
       "         [176],\n",
       "         ..., \n",
       "         [138],\n",
       "         [136],\n",
       "         [135]],\n",
       "\n",
       "        [[181],\n",
       "         [168],\n",
       "         [155],\n",
       "         ..., \n",
       "         [136],\n",
       "         [136],\n",
       "         [134]]],\n",
       "\n",
       "\n",
       "       [[[195],\n",
       "         [199],\n",
       "         [205],\n",
       "         ..., \n",
       "         [182],\n",
       "         [140],\n",
       "         [ 77]],\n",
       "\n",
       "        [[193],\n",
       "         [196],\n",
       "         [202],\n",
       "         ..., \n",
       "         [197],\n",
       "         [165],\n",
       "         [105]],\n",
       "\n",
       "        [[198],\n",
       "         [200],\n",
       "         [204],\n",
       "         ..., \n",
       "         [208],\n",
       "         [196],\n",
       "         [157]],\n",
       "\n",
       "        ..., \n",
       "        [[ 57],\n",
       "         [ 73],\n",
       "         [ 84],\n",
       "         ..., \n",
       "         [  3],\n",
       "         [ 20],\n",
       "         [ 33]],\n",
       "\n",
       "        [[ 61],\n",
       "         [ 73],\n",
       "         [ 96],\n",
       "         ..., \n",
       "         [  6],\n",
       "         [ 19],\n",
       "         [ 41]],\n",
       "\n",
       "        [[ 61],\n",
       "         [ 79],\n",
       "         [ 95],\n",
       "         ..., \n",
       "         [  6],\n",
       "         [ 15],\n",
       "         [ 38]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "28709/28709 [==============================] - 8s 280us/step - loss: 2.0006 - acc: 0.2512\n",
      "Epoch 2/25\n",
      "28709/28709 [==============================] - 7s 227us/step - loss: 1.6601 - acc: 0.3567\n",
      "Epoch 3/25\n",
      "28709/28709 [==============================] - 7s 228us/step - loss: 1.4978 - acc: 0.4213\n",
      "Epoch 4/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 1.3955 - acc: 0.4630\n",
      "Epoch 5/25\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 1.3263 - acc: 0.4906\n",
      "Epoch 6/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 1.2786 - acc: 0.5121\n",
      "Epoch 7/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 1.2374 - acc: 0.5262\n",
      "Epoch 8/25\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 1.2010 - acc: 0.5423\n",
      "Epoch 9/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 1.1682 - acc: 0.5565\n",
      "Epoch 10/25\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 1.1417 - acc: 0.5680\n",
      "Epoch 11/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 1.1127 - acc: 0.5771\n",
      "Epoch 12/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 1.0899 - acc: 0.5901\n",
      "Epoch 13/25\n",
      "28709/28709 [==============================] - 7s 231us/step - loss: 1.0603 - acc: 0.5978\n",
      "Epoch 14/25\n",
      "28709/28709 [==============================] - 7s 231us/step - loss: 1.0435 - acc: 0.6047\n",
      "Epoch 15/25\n",
      "28709/28709 [==============================] - 7s 231us/step - loss: 1.0243 - acc: 0.6125\n",
      "Epoch 16/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 0.9979 - acc: 0.6287\n",
      "Epoch 17/25\n",
      "28709/28709 [==============================] - 7s 228us/step - loss: 0.9691 - acc: 0.6324\n",
      "Epoch 18/25\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 0.9554 - acc: 0.6369\n",
      "Epoch 19/25\n",
      "28709/28709 [==============================] - 7s 231us/step - loss: 0.9271 - acc: 0.6488\n",
      "Epoch 20/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 0.9117 - acc: 0.6578\n",
      "Epoch 21/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 0.8842 - acc: 0.6702\n",
      "Epoch 22/25\n",
      "28709/28709 [==============================] - 7s 230us/step - loss: 0.8694 - acc: 0.6725\n",
      "Epoch 23/25\n",
      "28709/28709 [==============================] - 7s 229us/step - loss: 0.8452 - acc: 0.6837\n",
      "Epoch 24/25\n",
      "28709/28709 [==============================] - 7s 231us/step - loss: 0.8240 - acc: 0.6930\n",
      "Epoch 25/25\n",
      "28709/28709 [==============================] - 7s 231us/step - loss: 0.7963 - acc: 0.7056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f690c395dd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x/255, temp, batch_size=128, epochs=25,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for f in test['feature']:\n",
    "    temp = np.array(f.split(' ')).astype(int)\n",
    "    test_x.append(temp)\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_x = test_x.reshape((test_x.shape[0],48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSES = model.predict_classes(test_x/255,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_result(filename,predict_value):\n",
    "    id_ = []\n",
    "    for i in range(predict_value.shape[0]):\n",
    "        id_.append(str(i+1))\n",
    "    output = pd.DataFrame(columns=['id','label'])\n",
    "    output['id'] = id_\n",
    "    output['label'] = predict_value\n",
    "    output.to_csv(filename,index = False)\n",
    "    \n",
    "    print(output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>7148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7149</th>\n",
       "      <td>7149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>7150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7151</th>\n",
       "      <td>7151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>7152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>7153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>7154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7155</th>\n",
       "      <td>7155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>7156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>7157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>7158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>7159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>7160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>7161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>7163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>7164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>7165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>7166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>7167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>7168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>7169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>7170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>7171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>7172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>7173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>7174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>7175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>7176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>7177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0        0      0\n",
       "1        1      0\n",
       "2        2      0\n",
       "3        3      0\n",
       "4        4      0\n",
       "5        5      0\n",
       "6        6      0\n",
       "7        7      0\n",
       "8        8      0\n",
       "9        9      0\n",
       "10      10      0\n",
       "11      11      0\n",
       "12      12      0\n",
       "13      13      0\n",
       "14      14      0\n",
       "15      15      0\n",
       "16      16      0\n",
       "17      17      0\n",
       "18      18      0\n",
       "19      19      0\n",
       "20      20      0\n",
       "21      21      0\n",
       "22      22      0\n",
       "23      23      0\n",
       "24      24      0\n",
       "25      25      0\n",
       "26      26      0\n",
       "27      27      0\n",
       "28      28      0\n",
       "29      29      0\n",
       "...    ...    ...\n",
       "7148  7148      0\n",
       "7149  7149      0\n",
       "7150  7150      0\n",
       "7151  7151      0\n",
       "7152  7152      0\n",
       "7153  7153      0\n",
       "7154  7154      0\n",
       "7155  7155      0\n",
       "7156  7156      0\n",
       "7157  7157      0\n",
       "7158  7158      0\n",
       "7159  7159      0\n",
       "7160  7160      0\n",
       "7161  7161      0\n",
       "7162  7162      0\n",
       "7163  7163      0\n",
       "7164  7164      0\n",
       "7165  7165      0\n",
       "7166  7166      0\n",
       "7167  7167      0\n",
       "7168  7168      0\n",
       "7169  7169      0\n",
       "7170  7170      0\n",
       "7171  7171      0\n",
       "7172  7172      0\n",
       "7173  7173      0\n",
       "7174  7174      0\n",
       "7175  7175      0\n",
       "7176  7176      0\n",
       "7177  7177      0\n",
       "\n",
       "[7178 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
